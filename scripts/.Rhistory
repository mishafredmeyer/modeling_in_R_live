filter(sixtyTOthirty >= 1.05 & ninetyTOsixty >= 1.05 & onetwentyTOninety >= 1.05)
summary_buffer_comparison <- buffer_comparisons %>%
filter(sixtyTOthirty >= 1.05 & ninetyTOsixty >= 1.05 & onetwentyTOninety >= 1.05) %>%
group_by(Hylak_id) %>%
mutate(unique_years = n_distinct(year)) %>%
ungroup()
head(summary_buffer_comparison)
summary_buffer_comparison <- buffer_comparisons %>%
filter(sixtyTOthirty >= 1.05 & ninetyTOsixty >= 1.05 & onetwentyTOninety >= 1.05) %>%
group_by(Hylak_id) %>%
mutate(unique_years = n_distinct(year)) %>%
ungroup() %>%
filter(unique_years == 4)
summary_buffer_comparison
length(unique(summary_buffer_comparison$Hylak_id))
summary_buffer_comparison <- buffer_comparisons %>%
filter(sixtyTOthirty >= 1.01 & ninetyTOsixty >= 1.01 & onetwentyTOninety >= 1.01) %>%
group_by(Hylak_id) %>%
mutate(unique_years = n_distinct(year)) %>%
ungroup() %>%
filter(unique_years == 4)
length(unique(summary_buffer_comparison$Hylak_id))
length(unique(summary_buffer_comparison$Hylak_id))/1422499
summary_buffer_comparison <- buffer_comparisons %>%
filter(sixtyTOthirty >= 1.05 & ninetyTOsixty >= 1.05 & onetwentyTOninety >= 1.05) %>%
group_by(Hylak_id) %>%
mutate(unique_years = n_distinct(year)) %>%
ungroup() %>%
filter(unique_years == 4)
length(unique(summary_buffer_comparison$Hylak_id))/1422499
summary_buffer_comparison <- buffer_comparisons %>%
filter(sixtyTOthirty >= 1.1 & ninetyTOsixty >= 1.1 & onetwentyTOninety >= 1.1) %>%
group_by(Hylak_id) %>%
mutate(unique_years = n_distinct(year)) %>%
ungroup() %>%
filter(unique_years == 4)
length(unique(summary_buffer_comparison$Hylak_id))/1422499
glcp <- fread("E:/GLOBAL_LAKES_AREA/Final_GLCP/Data/Derived-products/glcp.csv",
integer64 = "character")
glcp_subset <- glcp %>%
filter(hylak_id %in% unique(summary_buffer_comparison$Hylak_id))
rm(glcp)
gc()
names(glcp_subset)
library(data.table)
library(tidyverse)
buffer_comparisons <- fread("E:/GLOBAL_LAKES_AREA/Buffer_Comparisons/summary_buffer_to_buffer_second_rebuild_data_20190601.csv",
integer64 = "character")
glcp <- fread("E:/GLOBAL_LAKES_AREA/Final_GLCP/Data/Derived-products/glcp.csv",
integer64 = "character")
summary_buffer_comparison <- buffer_comparisons %>%
filter(sixtyTOthirty >= 1.1 & ninetyTOsixty >= 1.1 & onetwentyTOninety >= 1.1) %>%
group_by(Hylak_id) %>%
mutate(unique_years = n_distinct(year)) %>%
ungroup() %>%
filter(unique_years == 4)
glcp_subset <- glcp %>%
filter(hylak_id %in% unique(summary_buffer_comparison$Hylak_id))
rm(glcp)
gc()
glcp_strat_subset <- glcp_subset %>%
sample_n(size = 50, weight = "Continent")
glcp_strat_subset <- glcp_subset %>%
sample_n(size = 50, weight = Continent)
names(glcp_subset)
glcp_strat_subset <- glcp_subset %>%
sample_n(size = 50, weight = continent)
glcp_strat_subset <- glcp_subset %>%
sample_n(size = 50, weight = as.factor(continent))
glcp_strat_subset <- glcp_subset %>%
select(hylak_id, continent) %>%
sample_n(size = 50, weight = as.factor(continent))
length(unique(glcp_strat_subset$hylak_id))
unique(glcp_strat_subset$hylak_id)
filter(glcp_subset, hylak_id == 1191551)
summary(glcp_subset)
glcp_strat_summary <- glcp_subset %>%
select(mean_monthly_precip:total_km2)
glcp_strat_summary <- glcp_subset %>%
select(mean_monthly_precip_mm:total_km2)
summary_table <- do.call(cbind,
lapply(data.frame(strat_check$seasonal_check,
strat_check$permanent_check,
strat_check$total_check,
strat_check$pop_check,
strat_check$precip_mean_check,
strat_check$precip_sum_check,
strat_check$temp_check),
summary)) %>%
t()
names(glcp_strat_summary)
summary_table <- do.call(cbind,
lapply(data.frame(glcp_strat_summary$seasonal_km2,
glcp_strat_summary$permanent_km2,
glcp_strat_summary$total_km2,
glcp_strat_summary$pop_sum,
glcp_strat_summary$mean_monthly_precip_mm,
glcp_strat_summary$total_precip_mm,
glcp_strat_summary$mean_monthly_temp_k),
summary)) %>%
t()
# Write summary table output
write.csv(x = summary_table,
file = "E:/GLOBAL_LAKES_AREA/scientific_data_revisions/percent_change_buffer_year_summary.csv",
row.names = FALSE)
# Write summary table output
write.csv(x = summary_table,
file = "E:/GLOBAL_LAKES_AREA/scientific_data_revisions/percent_change_buffer_year_summary.csv",
row.names = TRUE)
# Write summary table output
write.csv(x = summary_table,
file = "E:/GLOBAL_LAKES_AREA/scientific_data_revisions/percent_change_buffer_year_summary.csv",
row.names = TRUE)
summary_table
glcp <- fread("D:/Final_GLCP_post_peerreview/Data/Derived-products/glcp.csv",
integer64 = "character", header = TRUE)
library(data.table)
glcp <- fread("D:/Final_GLCP_post_peerreview/Data/Derived-products/glcp.csv",
integer64 = "character", header = TRUE)
names(glcp)
library(raster)
library(sf)
hydrolakes_shp <- raster("E:/GLOBAL_LAKES_AREA/HydroLAKES/HydroLAKES_polys_v10_shp/HydroLAKES_polys_v10.shp")
hydrolakes_shp <- st_read("E:/GLOBAL_LAKES_AREA/HydroLAKES/HydroLAKES_polys_v10_shp/HydroLAKES_polys_v10.shp")
library(tidyverse)
names(hydrolakes_shp)
hydrolakes_shp %>%
fitler(grepl(pattern = "flathead", x = Lake_name, ignore.case = TRUE))
hydrolakes_shp %>%
filter(grepl(pattern = "flathead", x = Lake_name, ignore.case = TRUE))
flathead <- hydrolakes_shp %>%
filter(grepl(pattern = "flathead", x = Lake_name, ignore.case = TRUE))
plot(flathead)
library(data.table)
glcp <- fread("C:/Users/michael.f.meyer/Dropbox/flathead_sewage/cleaned_data/glcp_data/glcp.csv",
integer64 = "character")
glcp <- fread("C:/Users/michael.f.meyer/Dropbox/flathead_sewage/cleaned_data/glcp_data/Derived-products/glcp.csv",
integer64 = "character")
library(devtools)
install_github("ropensci/FedData")
citation()
library(data.table)
basins <- fread("D:/glcp_analysis/data/inputs/all_valid_basins_all_vars.csv", integer64 = "character")
head(basins)
summary(basins)
library(rgdal)
lev02 <- readOGR("E:/glcp_analysis_merge/data/BasinATLAS_Data_v10_shp/BasinATLAS_v10_shp/BasinATLAS_v10_lev02.shp")
head(lev02)
library(tidyverse)
library(mgcv)
library(polynom)
bike_data <- read.csv("../data/day.csv",
header = TRUE)
head(bike_data)
setwd("C:/Users/michael.f.meyer/Dropbox/modeling_in_R/scripts")
bike_data <- read.csv("../data/day.csv",
header = TRUE)
head(bike_data)
ggplot(bike_data, aes(atemp*50, (cnt))) +
geom_point() +
xlab("Feeling Temperature") +
ylab("Total bikes rented")
# Create a subset of hte data
bike_linear_data <- bike_data %>%
mutate(feeling_temperature = atemp*50) %>%
select(feeling_temperature, cnt)
# Build a linear model
linear_model <- lm(formula = cnt ~ feeling_temperature,
data = bike_linear_data)
# Assess the model
summary(linear_model)
# Assess model object structure
str(linear_model)
# Extract R-squared
r_squared <- summary(linear_model)$r.squared
# Extract p-value
p_value <- summary(linear_model)$coefficients[2, 4]
# Extract slope
slope <- summary(linear_model)$coefficients[2, 1]
# Extract y-intercept
y_intercept <- summary(linear_model)$coefficients[1, 1]
hist(linear_model$residuals)
bike_linear_data$predicted_cnt <- predict(linear_model)
bike_linear_data$residuals <- residuals(linear_model)
# 1. Visualize model and points
ggplot(data = bike_linear_data,
mapping = aes(x = feeling_temperature, y = cnt)) +
geom_point(alpha = 0.33)+
geom_smooth(method = "lm", se = TRUE) +
scale_fill_viridis_c(option = "plasma", name = "Number of\nPoints") +
theme_minimal()
# 2. Group points into hexbins
ggplot(data = bike_linear_data,
mapping = aes(x = feeling_temperature, y = cnt)) +
geom_hex(bins = 10)+
geom_smooth(method = "lm", se = TRUE) +
scale_fill_viridis_c(option = "plasma", name = "Number of\nPoints") +
theme_minimal()
ggplot(data = bike_linear_data,
mapping = aes(x = feeling_temperature, y = cnt)) +
geom_smooth(method = "lm", se = TRUE) +
geom_segment(mapping = aes(xend = feeling_temperature, yend = predicted_cnt),
alpha = 0.2)
# 3. Lines and color points for residuals.
# We will build this plot incrementally.
ggplot(data = bike_linear_data,
mapping = aes(x = feeling_temperature, y = cnt)) +
geom_smooth(method = "lm", se = TRUE) +
geom_segment(mapping = aes(xend = feeling_temperature, yend = predicted_cnt),
alpha = 0.2) +
geom_point(mapping = aes(color = abs(residuals))) +
scale_color_viridis_c(option = "plasma", name = "Residual\nTemperature (C)") +
theme_minimal()
prediction_data <- data.frame(feeling_temperature = seq(from = 0, to = 50, by = 0.25))
prediction_data$predicted_cnt <- predict(object = linear_model, newdata = prediction_data)
ggplot() +
geom_point(data = bike_data, mapping = aes(atemp*50, (cnt))) +
geom_point(data = prediction_data, mapping = aes(feeling_temperature,
predicted_cnt),
shape = 18) +
annotate(geom = "label", label = paste("Count = ", round(slope, 2),
"(Feeling Temperature) + ",
round(y_intercept,2)),
x = 15, y = 7500, size = 4) +
xlab("Feeling Temperature") +
ylab("Total bikes rented")
# Create a new dataset for multiple linear regression
# with continuous variables.
multiple_bike_data <- bike_data %>%
mutate(feeling_temperature = atemp * 50,
humidity = hum * 100,
windiness = windspeed * 67) %>%
select(feeling_temperature, humidity, humidity, windiness, cnt)
# First make a model where interactions are considered.
multiple_linear_model <- lm(formula = cnt ~ feeling_temperature * humidity * windiness,
data = multiple_bike_data)
summary(multiple_linear_model)
# Assess the pairs plot for cross-correlations
pairs(multiple_bike_data[ , 1:3])
# Create a function to put correlation value in the upper panel.
# This function can be found in the documentation for pairs.
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y))
txt <- format(c(r, 0.123456789), digits = digits)[1]
txt <- paste0(prefix, txt)
if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex.cor * r)
}
# Rerun pairs with upper panel showing correlation values.
pairs(multiple_bike_data[ , 1:3], upper.panel = panel.cor)
# Second make a model where interactions are NOT considered.
multiple_linear_model_no_inter <- lm(formula = cnt ~ feeling_temperature + humidity + windiness,
data = multiple_bike_data)
summary(multiple_linear_model_no_inter)
# Calculate the AIC of each linear model
# i.e., all interactions vs no interactions
AIC(multiple_linear_model)
AIC(multiple_linear_model_no_inter)
# Create data subset
mixed_bike_data <- bike_data %>%
mutate(feeling_temperature = atemp * 50,
humidity = hum * 100,
windiness = windspeed * 67,
weather_type = ifelse(weathersit == 1, "Clear", NA),
weather_type = ifelse(weathersit == 2, "Misty_Cloudy", weather_type),
weather_type = ifelse(weathersit == 3, "Light_precip", weather_type),
weather_type = ifelse(weathersit == 4, "Heavy_precip", weather_type),
weather_type = as.factor(weather_type)) %>%
select(feeling_temperature, humidity, windiness, weather_type, cnt)
# Check to be sure that there are no NAs
summary(mixed_bike_data)
# Build the model
mixed_type_model <- lm(cnt ~ feeling_temperature * humidity * windiness * weather_type,
data = mixed_bike_data)
summary(mixed_type_model)
ggplot(data = mixed_bike_data, aes(x = humidity,
y = cnt)) +
geom_smooth(method = "lm") +
geom_point(alpha = 0.2) +
facet_grid(~weather_type)
ggplot(data = mixed_bike_data, aes(x = windiness,
y = cnt)) +
geom_smooth(method = "lm") +
geom_point(alpha = 0.2) +
facet_grid(~weather_type)
ggplot(data = mixed_bike_data, aes(x = feeling_temperature,
y = cnt)) +
geom_smooth(method = "lm") +
geom_point(alpha = 0.2) +
facet_grid(~weather_type)
ggplot(data = mixed_bike_data, aes(x = feeling_temperature,
y = windiness,
color = cnt)) +
geom_point(alpha = 0.7) +
scale_color_viridis_c() +
facet_grid(~weather_type) +
theme_minimal()
ggplot(data = mixed_bike_data, aes(x = feeling_temperature,
y = humidity,
color = cnt)) +
geom_point(alpha = 0.7) +
scale_color_viridis_c() +
facet_grid(~weather_type) +
theme_minimal()
ggplot(data = mixed_bike_data, aes(x = windiness,
y = humidity,
color = cnt)) +
geom_point(alpha = 0.7) +
scale_color_viridis_c() +
facet_grid(~weather_type) +
theme_minimal()
# Create a special dataset
bike_nonlinear_data <- bike_data %>%
mutate(feeling_temperature = atemp*50) %>%
select(feeling_temperature, cnt)
# Remind ourselves what these data looked like
ggplot(bike_nonlinear_data, aes(feeling_temperature, (cnt))) +
geom_point() +
xlab("Feeling Temperature") +
ylab("Total bikes rented")
# Build the model
polynomial_bike_model <- lm(formula = cnt ~ poly(x = feeling_temperature, degree = 3),
data= bike_nonlinear_data)
summary(polynomial_bike_model)
prediction_data <- data.frame(feeling_temperature = seq(from = 0, to = 45, by = 0.25))
prediction_data$predicted_cnt <- predict(object = polynomial_bike_model,
newdata = prediction_data)
third_order_coef <- round(coef(polynomial_bike_model)[[4]],2)
second_order_coef <- round(coef(polynomial_bike_model)[[3]],2)
first_order_coef <- round(coef(polynomial_bike_model)[[2]],2)
y_intercept <- third_order_coef <- round(coef(polynomial_bike_model)[[1]],2)
equation <- as.character(signif(as.polynomial(coef(polynomial_bike_model)), 3))
ggplot() +
geom_point(data = bike_data, mapping = aes(atemp*50, (cnt))) +
geom_point(data = prediction_data, mapping = aes(feeling_temperature,
predicted_cnt),
shape = 18, color = "blue") +
annotate(geom = "label", label = equation,
x = 15, y = 7500, size = 4, parse = TRUE) +
xlab("Feeling Temperature") +
ylab("Total bikes rented") +
theme_minimal()
# Build the model
polynomial_bike_model <- lm(formula = cnt ~ poly(x = I(feeling_temperature^3)),
data= bike_nonlinear_data)
summary(polynomial_bike_model)
prediction_data <- data.frame(feeling_temperature = seq(from = 0, to = 45, by = 0.25))
prediction_data$predicted_cnt <- predict(object = polynomial_bike_model,
newdata = prediction_data)
ggplot() +
geom_point(data = bike_data, mapping = aes(atemp*50, (cnt))) +
geom_point(data = prediction_data, mapping = aes(feeling_temperature,
predicted_cnt),
shape = 18, color = "blue") +
xlab("Feeling Temperature") +
ylab("Total bikes rented") +
theme_minimal()
library(mgcv)
bike_gam_model <- gam(cnt ~ s(feeling_temperature),
data = bike_nonlinear_data,
method = "REML", gamma = 1)
summary(bike_gam_model)
plot(bike_gam_model)
bike_gam_model <- gam(cnt ~ s(feeling_temperature),
data = bike_nonlinear_data,
method = "REML", gamma = 0.01)
summary(bike_gam_model)
plot(bike_gam_model)
bike_gam_model <- gam(cnt ~ s(feeling_temperature),
data = bike_nonlinear_data,
method = "REML", gamma = 10)
summary(bike_gam_model)
plot(bike_gam_model)
bike_gam_model <- gam(cnt ~ s(feeling_temperature),
data = bike_nonlinear_data,
method = "REML", gamma = 1)
summary(bike_gam_model)
plot(bike_gam_model)
prediction_data <- data.frame(feeling_temperature = seq(from = 0, to = 50, by = 0.25))
prediction_data$predicted_cnt <- predict(object = bike_gam_model,
newdata = prediction_data)
ggplot() +
geom_point(data = bike_data, mapping = aes(atemp*50, (cnt))) +
geom_point(data = prediction_data, mapping = aes(feeling_temperature,
predicted_cnt),
shape = 18) +
xlab("Feeling Temperature") +
ylab("Total bikes rented")
# First look at some data that we will be modeling
ggplot(bike_data, aes(registered)) +
geom_histogram() +
facet_grid(~workingday)
ggplot(bike_data, aes(registered)) +
geom_density() +
facet_grid(~workingday)
bike_data %>%
group_by(workingday) %>%
summarize(mean_registered = mean(registered))
logistic_model <- glm(formula = workingday ~ registered, data = bike_data,
family = binomial())
summary(logistic_model)
prediction_data$predicted_cnt <- predict(object = logistic_model,
newdata = prediction_data,
type = "response")
ggplot() +
geom_point(data = bike_data, mapping = aes(registered, (workingday))) +
geom_point(data = prediction_data, mapping = aes(registered,
predicted_cnt),
shape = 18) +
xlab("Is it is a working day?") +
ylab("Registered bike reservations")
bike_data %>%
group_by(workingday) %>%
summarize(mean_registered = mean(registered))
logistic_model <- glm(formula = workingday ~ registered, data = bike_data,
family = binomial())
summary(logistic_model)
prediction_data <- data.frame(registered = seq(from = 0, to = 7000, by = 10))
prediction_data$predicted_cnt <- predict(object = logistic_model,
newdata = prediction_data,
type = "response")
ggplot() +
geom_point(data = bike_data, mapping = aes(registered, (workingday))) +
geom_point(data = prediction_data, mapping = aes(registered,
predicted_cnt),
shape = 18) +
xlab("Is it is a working day?") +
ylab("Registered bike reservations")
# Create a training dataset
training_bike_data <- bike_data %>%
rownames_to_column() %>%
rename("index" = "rowname") %>%
mutate(feeling_temperature = atemp*50) %>%
select( index, feeling_temperature, registered, workingday) %>%
sample_frac(., size = 0.75, weight = as.factor(workingday))
# Create a test dataset
test_bike_data <- bike_data %>%
rownames_to_column() %>%
rename("index" = "rowname") %>%
mutate(feeling_temperature = atemp*50) %>%
select( index, feeling_temperature, registered, workingday) %>%
filter(!(index %in% training_bike_data$index))
# Build a linear model on the training dataset
training_bike_model <- lm(registered ~ feeling_temperature, data = training_bike_data)
summary(test_bike_model)
# Create a test dataset
test_bike_data <- bike_data %>%
rownames_to_column() %>%
rename("index" = "rowname") %>%
mutate(feeling_temperature = atemp*50) %>%
select( index, feeling_temperature, registered, workingday) %>%
filter(!(index %in% training_bike_data$index))
# Build a linear model on the training dataset
training_bike_model <- lm(registered ~ feeling_temperature, data = training_bike_data)
summary(test_bike_model)
# Predict values for the test dataset
test_bike_data$predicted_registered <- predict.lm(training_bike_model,
newdata = test_bike_data)
# Calculate RMSE for predictions vs. observations
rmse <- test_bike_data %>%
mutate(square_residual = (predicted_registered - registered)^2) %>%
summarize(rmse = sqrt(sum(square_residual)/nrow(test_bike_data)))
rmse
nreps <- 1000
rmse_repo <- rep(NA, nreps)
for(i in 1:nreps){
training_bike_data <- bike_data %>%
rownames_to_column() %>%
rename("index" = "rowname") %>%
mutate(feeling_temperature = atemp*50) %>%
select( index, feeling_temperature, registered, workingday) %>%
sample_frac(., size = 0.75, weight = as.factor(workingday))
test_bike_data <- bike_data %>%
rownames_to_column() %>%
rename("index" = "rowname") %>%
mutate(feeling_temperature = atemp*50) %>%
select( index, feeling_temperature, registered, workingday) %>%
filter(!(index %in% training_bike_data$index))
training_bike_model <- lm(registered ~ feeling_temperature, data = training_bike_data)
summary(training_bike_model)
test_bike_data$predicted_registered <- predict.lm(training_bike_model,
newdata = test_bike_data)
rmse_repo[i] <- test_bike_data %>%
mutate(square_residual = (predicted_registered - registered)^2) %>%
summarize(rmse = sqrt(sum(square_residual)/nrow(test_bike_data)))
}
# Assess the distribution of values
hist(unlist(rmse_repo))
# Create a dataset for the linear model using all data
linear_bike_data <- bike_data %>%
rownames_to_column() %>%
rename("index" = "rowname") %>%
mutate(feeling_temperature = atemp*50) %>%
select( index, feeling_temperature, registered, workingday)
# Build the model
whole_linear_model <- lm(registered ~ feeling_temperature,
data = linear_bike_data)
# Predict values
linear_bike_data$predicted_registered <- predict(whole_linear_model)
# Calculate RMSE
rmse_whole_data <- linear_bike_data %>%
mutate(square_residual = (predicted_registered - registered)^2) %>%
summarize(rmse = sqrt(sum(square_residual)/nrow(linear_bike_data)))
unlist(rmse_whole_data)
# Plot the distribution and our observed RMSE with the whole data
ggplot() +
geom_histogram(data = data.frame(rmse = unlist(rmse_repo)), aes(x = rmse)) +
geom_vline(data = data.frame(rmse = unlist(rmse_whole_data)),
aes(xintercept = rmse))
